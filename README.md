# Big-Mart-Sales-Data-Cleaning-Python-Script

Hello there!!

Welcome to my data-cleaning script â€“ a small but powerful part of a bigger story.
This project began with one simple question:

    Whatâ€™s hiding inside the messy sales data of a retail giant like Big Mart?"

As I opened the Excel file, I realized â€“ like every real-world dataset â€“ it had its share of problems:
âŒ Missing values
âŒ Zero entries that shouldnâ€™t be zero
âŒ Inconsistent labels
âŒ And a few quirks that only a data lover could spot

ğŸ“‚ What's in This Project?
File: project_1.py
Purpose: Clean and prep the raw Big_mart.xlsx dataset into a well-structured .csv file you can actually work with.

What Does the Script Do?

ğŸ—‚ï¸ Step 1: Reading the Raw Data
I loaded the Excel sheet using pandas, setting the stage for transformation.


ğŸ•³ï¸ Step 2: Filling the Gaps
ğŸ§ª Item Weights were missing?so, I filled them in using the median â€” a fair and robust estimate.

ğŸ¬ Outlet Size was unknown in some rows. I marked them as "NA" â€” better than pretending we know.

ğŸš« Step 3: Fixing the Oddities
- 0 Item Visibility? Thatâ€™s just wrong â€” replaced those with the median again.
- Then I added a twist: labeled each product as "Low" or "High" visibility â€” making it human-readable.

ğŸ§¹ Step 4: Tidying Up
- Rounded values in Item_MRP, Item_Outlet_Sales, and Item_Visibility for cleaner presentation.
- Standardized confusing entries in Item_Fat_Content. (Goodbye "LF" and "reg", hello "Low Fat" and "Regular")

ğŸ•µï¸â€â™€ï¸ Step 5: Duplicate Detection
I also checked for repeated Item_Identifier values â€” just to make sure we're not counting the same thing twice.

ğŸ’¾ Step 6: Saving the Clean Version
Finally, I exported the polished data to csv.

âœ¨ Final Thoughts
This project may look simple, but it's the first building block in turning raw, chaotic data into meaningful insights.

Whether you're predicting sales or building a dashboard, clean data is your best friend.
